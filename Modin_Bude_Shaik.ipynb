{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDriIbfa5lwD"
   },
   "source": [
    "**Problem statement**: To build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution which can evaluate images and alert the dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18348,
     "status": "ok",
     "timestamp": 1710148826561,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "aEGHlUex78G5",
    "outputId": "110596e0-2b26-40a2-8deb-2d14fadf77ba"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqT8SHQ50S3p"
   },
   "source": [
    "**Goal**: To create a multiclass classification model using a custom convolutional neural network in tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvdV0dn-0tKJ"
   },
   "source": [
    "**Data Summary:**\n",
    "\n",
    "The dataset consists of 2357 images of malignant and benign oncological diseases, which were formed from the International Skin Imaging Collaboration (ISIC). All images were sorted according to the classification taken with ISIC, and all subsets were divided into the same number of images, with the exception of melanomas and moles, whose images are slightly dominant.\n",
    "\n",
    "The data set contains the following diseases:\n",
    "1. Actinic keratosis\n",
    "2. Basal cell carcinoma\n",
    "3. Dermatofibroma\n",
    "4. Melanoma\n",
    "5. Nevus\n",
    "6. Pigmented benign keratosis\n",
    "7. Seborrheic keratosis\n",
    "8. Squamous cell carcinoma\n",
    "9. Vascular lesion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvR7ppk77v31"
   },
   "source": [
    "### Importing Skin Cancer Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfcpIXQZN2Rh"
   },
   "source": [
    "### Importing all the important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 544,
     "status": "ok",
     "timestamp": 1710148830964,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "WC8xCQuELWms"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import PIL\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.python.keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "#from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpUsRQwOOL72"
   },
   "source": [
    "This assignment uses a dataset of about 2357 images of skin cancer types. The dataset contains 9 sub-directories in each train and test subdirectories. The 9 sub-directories contains the images of 9 skin cancer types respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1710148834911,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "D57L-ovIKtI4"
   },
   "outputs": [],
   "source": [
    "# Defining the path for train and test images\n",
    "## Todo: Update the paths of the train and test dataset\n",
    "root_path = '/content/gdrive/MyDrive/CNN/Skin_Data_Store'\n",
    "data_dir_train = pathlib.Path(root_path + '/Train')\n",
    "data_dir_test = pathlib.Path(root_path + '/Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10379,
     "status": "ok",
     "timestamp": 1710148848672,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "DqksN1w5Fu-N",
    "outputId": "15d1e17f-9b17-4aa0-c7cc-2e46b5538507"
   },
   "outputs": [],
   "source": [
    "image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n",
    "print(image_count_train)\n",
    "image_count_test = len(list(data_dir_test.glob('*/*.jpg')))\n",
    "print(image_count_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8HkfW3jPJun"
   },
   "source": [
    "### Load using keras.preprocessing\n",
    "\n",
    "Let's load these images off disk using the helpful image_dataset_from_directory utility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDBKZG3jPcMc"
   },
   "source": [
    "### Create a dataset\n",
    "\n",
    "Define some parameters for the loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 468,
     "status": "ok",
     "timestamp": 1710148860504,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "VLfcXcZ9LjGv"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5f5y43GPog1"
   },
   "source": [
    "Use 80% of the images for training, and 20% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2553,
     "status": "ok",
     "timestamp": 1710148864726,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "G1BWmDzr7w-5",
    "outputId": "1eb69e81-d6f3-4bd6-d748-f3b45fc7c3e2"
   },
   "outputs": [],
   "source": [
    "## Write your train dataset here\n",
    "## Note use seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
    "## Note, make sure your resize your images to the size img_height*img_width, while writting the dataset\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2435,
     "status": "ok",
     "timestamp": 1710148869435,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "LYch6-SR-i2g",
    "outputId": "8a07845f-7457-466d-f449-6cb6dc925912"
   },
   "outputs": [],
   "source": [
    "## Write your validation dataset here\n",
    "## Note use seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
    "## Note, make sure your resize your images to the size img_height*img_width, while writting the dataset\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 412,
     "status": "ok",
     "timestamp": 1710148871770,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "s1V0Okk-40v3",
    "outputId": "38528e66-38e0-403f-959d-8807430195ce"
   },
   "outputs": [],
   "source": [
    "## Write your test dataset here\n",
    "## Note use seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n",
    "## Note, make sure your resize your images to the size img_height*img_width, while writting the dataset\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_test,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1710148873728,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "Bk0RV7G7-nad",
    "outputId": "ca3950f4-d8b8-4e6c-b6e1-f3183b4c2027"
   },
   "outputs": [],
   "source": [
    "# List out all the classes of skin cancer and store them in a list.\n",
    "# You can find the class names in the class_names attribute on these datasets.\n",
    "# These correspond to the directory names in alphabetical order.\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbsm5oYiQH_b"
   },
   "source": [
    "### Visualize the data\n",
    "#### Todo, create a code to visualize one instance of all the nine classes present in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 829
    },
    "executionInfo": {
     "elapsed": 40180,
     "status": "ok",
     "timestamp": 1710078173628,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "tKILZ48I-q1k",
    "outputId": "65a5f2a0-911c-4a53-f155-f095a9997cca"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cAZPYaeQjQy"
   },
   "source": [
    "The `image_batch` is a tensor of the shape `(32, 180, 180, 3)`. This is a batch of 32 images of shape `180x180x3` (the last dimension refers to color channels RGB). The `label_batch` is a tensor of the shape `(32,)`, these are corresponding labels to the 32 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzVXBHiyQ7_I"
   },
   "source": [
    "`Dataset.cache()` keeps the images in memory after they're loaded off disk during the first epoch.\n",
    "\n",
    "`Dataset.prefetch()` overlaps data preprocessing and model execution while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1710148878949,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "7wZlKRBEGNtU"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JEAF6-sRyz8"
   },
   "source": [
    "### Create the model\n",
    "#### Todo: Create a CNN model, which can accurately detect 9 classes present in the dataset. Use ```layers.experimental.preprocessing.Rescaling``` to normalize pixel values between (0,1). The RGB channel values are in the `[0, 255]` range. This is not ideal for a neural network. Here, it is good to standardize values to be in the `[0, 1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 599,
     "status": "ok",
     "timestamp": 1710148881640,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "d_Fzwx-N5sn1"
   },
   "outputs": [],
   "source": [
    "preprocessing_layers = [\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(180, 180, 3))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1179,
     "status": "ok",
     "timestamp": 1710148885196,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "ync9xoW7GZgn",
    "outputId": "443a3c4f-1d7e-4221-f4c9-d8f7ee7879c7"
   },
   "outputs": [],
   "source": [
    "### Your code goes here\n",
    "\n",
    "input_shape = (180,180,3)\n",
    "lr = 1e-5\n",
    "init = 'normal'\n",
    "activ = 'relu'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(180, 180, 3)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "## Number of classes is 9\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDKzJmHwSCtt"
   },
   "source": [
    "### Compile the model\n",
    "Choose an appropirate optimiser and loss function for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XB8wKtiPGe1j"
   },
   "outputs": [],
   "source": [
    "### Todo, choose an appropirate optimiser and loss function\n",
    "\n",
    "optimizer = 'adam'\n",
    "loss_fn = \"binary_crossentropy\"\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 839,
     "status": "ok",
     "timestamp": 1710054531916,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "_ZGWN4MZGhtJ",
    "outputId": "b8d5f792-0d6e-4f2b-97f5-836f48089a43"
   },
   "outputs": [],
   "source": [
    "# View the summary of all layers\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljD_83rwSl5O"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5696974,
     "status": "ok",
     "timestamp": 1710061036296,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "Kkfw2rJXGlYC",
    "outputId": "743741e4-c73b-4cf3-f705-f9dfbd6a74a4"
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  batch_size=batch_size,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3679V8OShSE"
   },
   "source": [
    "### Visualizing training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "executionInfo": {
     "elapsed": 2470,
     "status": "ok",
     "timestamp": 1710062389530,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "R1xkgk5nGubz",
    "outputId": "4ce801dd-564c-4dc4-ca65-1c049faaa3c7"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvPphJYuSZhK"
   },
   "source": [
    "#### Model Overfit or Underfit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 103048,
     "status": "ok",
     "timestamp": 1710062534848,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "AQO0_mZCLSWr",
    "outputId": "0c9e7f78-3650-4bb8-cfb4-263bbe2be45f"
   },
   "outputs": [],
   "source": [
    "\n",
    "loss, accuracy = model.evaluate(train_ds, verbose=1,)\n",
    "loss_v, accuracy_v = model.evaluate(val_ds, verbose=1)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Validation Accuracy: \",accuracy_v)\n",
    "print(\"Loss: \",loss)\n",
    "print(\"Validation Loss\", loss_v)\n",
    "\n",
    "\n",
    "# Thus we can clearly that model Overfit and we need to chose right data augumentation strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 512,
     "status": "ok",
     "timestamp": 1710062715344,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "22hljAl6GykA",
    "outputId": "4774f454-3f6c-4384-adb4-19356b9719a7"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "image_class = ['nevus','melanoma','basal_cell_caricoma','actinic_keratosis','vasc_lesion','dermatofibroma', 'pigmented_keratosis', 'seborrheic_keratosis', 'squamous_carci']\n",
    "\n",
    "train_batches = datagen.flow_from_directory(data_dir_train,\n",
    "    target_size = (180,180),\n",
    "    classes = image_class,\n",
    "    batch_size = 64\n",
    " )\n",
    "\n",
    "valid_batches = datagen.flow_from_directory(data_dir_test,\n",
    "    target_size = (180,180),\n",
    "    classes = image_class,\n",
    "    batch_size = 64\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 829
    },
    "executionInfo": {
     "elapsed": 4421,
     "status": "ok",
     "timestamp": 1710062734109,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "XEjPWh8GG0C7",
    "outputId": "14e0b570-94a5-479b-d591-026c42488b7b"
   },
   "outputs": [],
   "source": [
    "# visualize how your augmentation strategy works for one instance of training image.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhKDHlUdTuSX"
   },
   "source": [
    "\n",
    "### Create the model, compile and train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1394,
     "status": "ok",
     "timestamp": 1710063399026,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "W3V4l-O9G3dM",
    "outputId": "7b64acf9-61cb-4f87-edef-03a3856c35c9"
   },
   "outputs": [],
   "source": [
    "## You can use Dropout layer if there is an evidence of overfitting in your findings\n",
    "input_shape = (180,180,3)\n",
    "lr = 1e-5\n",
    "init = 'normal'\n",
    "activ = 'relu'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Increse the model size by adding another 32 layer\n",
    "model.add(tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(180, 180, 3)))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "# Max Pool size of 2*2\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "# Adding Dropout Layer\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding = 'Same'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding = 'Same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(9, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfUWFp96UIAN"
   },
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-7yTm8IG8zR"
   },
   "outputs": [],
   "source": [
    "#optimizer = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxROM6O_cHnp"
   },
   "source": [
    "In order to make the optimizer converge faster and closest to the global minimum of the loss function, i used an annealing method of the learning rate (LR).\n",
    "\n",
    "The LR is the step by which the optimizer walks through the 'loss landscape'. The higher LR, the bigger are the steps and the quicker is the convergence. However the sampling is very poor with an high LR and the optimizer could probably fall into a local minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3jffRAAcBwS"
   },
   "outputs": [],
   "source": [
    "# Set a learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    factor=0.5,\n",
    "    min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kC-D_RWOURp6"
   },
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4323289,
     "status": "ok",
     "timestamp": 1710068130732,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "UcPfkUASHBf9",
    "outputId": "fe345d8e-9665-4df0-fe14-fff3267a716a"
   },
   "outputs": [],
   "source": [
    "## Your code goes here, note: train your model for 20 epochs\n",
    "epochs = 20\n",
    "batch_size = 10\n",
    "history = model.fit(train_batches,\n",
    "  epochs = epochs, verbose = 1, validation_data=valid_batches , callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IhNOKtSyUYzC"
   },
   "source": [
    "### Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "executionInfo": {
     "elapsed": 1578,
     "status": "ok",
     "timestamp": 1710069058638,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "vjN_F4QxHIsh",
    "outputId": "a7d561b0-bf40-4e9b-c332-90fee321b4d3"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "print(history.history.keys, \":\")\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 793
    },
    "executionInfo": {
     "elapsed": 673,
     "status": "error",
     "timestamp": 1710069068327,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "iABW_O4seWnd",
    "outputId": "88c42363-b0bd-43a4-ffcb-c0091a9922e1"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(train_ds, verbose=1,)\n",
    "loss_v, accuracy_v = model.evaluate(val_ds, verbose=1)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Validation Accuracy: \",accuracy_v)\n",
    "print(\"Loss: \",loss)\n",
    "print(\"Validation Loss\", loss_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-AUR_b7UcaK"
   },
   "source": [
    "#### Write your findings after the model fit, see if there is an evidence of model overfit or underfit. Do you think there is some improvement now as compared to the previous model run?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TdDi4u-VTkW"
   },
   "source": [
    "#### Find the distribution of classes in the training dataset.\n",
    "#### **Context:** Many times real life datasets can have class imbalance, one class can have proportionately higher number of samples compared to the others. Class imbalance can have a detrimental effect on the final model quality. Hence as a sanity check it becomes important to check what is the distribution of classes in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 731915,
     "status": "ok",
     "timestamp": 1710149642099,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "hya16hY996kW",
    "outputId": "fe6c9307-736a-4b7d-a603-c1d9d8702681"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data = dict()\n",
    "\n",
    "for i in class_names:\n",
    "  data[i] = []\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds:\n",
    "  for i in range(9):\n",
    "    data[class_names[labels[i]]].append(images[i].numpy().astype(\"uint8\"))\n",
    "\n",
    "for i in data:\n",
    "  data[i] = len(data[i])\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(20)\n",
    "f.set_figheight(20)\n",
    "\n",
    "plt.bar(range(len(data)), list(data.values()), align='center')\n",
    "plt.xticks(range(len(data)), list(data.keys()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hb-stKyHPf8v"
   },
   "source": [
    "#### Rectify the class imbalance\n",
    "#### **Context:** You can use a python package known as `Augmentor` (https://augmentor.readthedocs.io/en/master/) to add more samples across all classes so that none of the classes have very few samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4csQL1dvO0b2"
   },
   "source": [
    "\n",
    "#### - Which class has the least number of samples? - **Actinic Keratosos** and **Seborrheic keratosis**\n",
    "#### - Which classes dominate the data in terms proportionate number of samples?\n",
    "**Pigmented benign keratosis** dominates the data of count more than 100 in training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6502,
     "status": "ok",
     "timestamp": 1710152583801,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "ItAg4rU-SzJh",
    "outputId": "94c943bf-a0b1-4d94-a0e7-28dd6375f312"
   },
   "outputs": [],
   "source": [
    "!pip install Augmentor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZKzTe3zWL4O"
   },
   "source": [
    "To use `Augmentor`, the following general procedure is followed:\n",
    "\n",
    "1. Instantiate a `Pipeline` object pointing to a directory containing your initial image data set.<br>\n",
    "2. Define a number of operations to perform on this data set using your `Pipeline` object.<br>\n",
    "3. Execute these operations by calling the `Pipeline’s` `sample()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 414169,
     "status": "ok",
     "timestamp": 1710153001152,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "9Egt9EHjR-Dd",
    "outputId": "20e4b4b2-745b-4b77-f4e4-f822df08c2b6"
   },
   "outputs": [],
   "source": [
    "path_to_training_dataset=\"/content/gdrive/MyDrive/CNN/Skin_Data_Store/Train/\"\n",
    "# data_dir_train = pathlib.Path(root_path + '/Train')\n",
    "import Augmentor\n",
    "for i in class_names:\n",
    "    p = Augmentor.Pipeline(path_to_training_dataset + i)\n",
    "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
    "    p.sample(500) ## We are adding 500 samples per class to make sure that none of the classes are sparse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcBIFZGbWuFa"
   },
   "source": [
    "Augmentor has stored the augmented images in the output sub-directory of each of the sub-directories of skin cancer types.. Lets take a look at total count of augmented images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 544,
     "status": "ok",
     "timestamp": 1710154507833,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "jxWcMqZhdRWz",
    "outputId": "b1e1aa8e-2541-401c-b5cc-2281de37a5f4"
   },
   "outputs": [],
   "source": [
    "image_count_train = len(list(data_dir_train.glob('*/output/*.jpg')))\n",
    "print(image_count_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJ5KarKq4kWJ"
   },
   "source": [
    "### Lets see the distribution of augmented data after adding new images to the original training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 610,
     "status": "ok",
     "timestamp": 1710154513632,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "6tODrYIY2nxJ",
    "outputId": "410b0378-1bf6-4f2f-8daf-3ec1cc425d5a"
   },
   "outputs": [],
   "source": [
    "path_list = [x for x in glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
    "path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1710154520493,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "nZvVdF7g3E1z",
    "outputId": "f786de52-ccda-4676-a03a-7a2959616385"
   },
   "outputs": [],
   "source": [
    "lesion_list_new = [os.path.basename(os.path.dirname(os.path.dirname(y))) for y in glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
    "lesion_list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1023,
     "status": "ok",
     "timestamp": 1710154527915,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "Ch0MuKvFVr7O",
    "outputId": "be9a932a-041b-4e19-bdc6-5ff47a648255"
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Increse the model size by adding another 32 layer\n",
    "model.add(tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(180, 180, 3)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=(img_height, img_width,3)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "\n",
    "# Max Pool size of 2*2\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "# Adding Dropout Layer\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding = 'Same'))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding = 'Same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1710154534964,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "okcqVFAA2nxK"
   },
   "outputs": [],
   "source": [
    "dataframe_dict_new = dict(zip(path_list, lesion_list_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 367,
     "status": "ok",
     "timestamp": 1710154540593,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "njzBxTNT2nxK"
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(list(dataframe_dict_new.items()),columns = ['Path','Label'])\n",
    "new_df = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1710154545710,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "5j45rmxd2nxK",
    "outputId": "d4a560f6-be8f-446c-fd74-7c2ae26b5788"
   },
   "outputs": [],
   "source": [
    "new_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9NirFBvGPmgI"
   },
   "source": [
    "So, now we have added 500 images to all the classes to maintain some class balance. We can add more images as we want to improve training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EnspeMbRWNs"
   },
   "source": [
    "#### Train the model on the data created using Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 358,
     "status": "ok",
     "timestamp": 1710154550945,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "hFcj1XgndRWz"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0haOU11Ey8ey"
   },
   "source": [
    "#### Create a training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5138,
     "status": "ok",
     "timestamp": 1710154560982,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "H4ZY11judRWz",
    "outputId": "3593c451-aa87-4e17-a0f0-a03065dedb69"
   },
   "outputs": [],
   "source": [
    "data_dir_train=\"/content/gdrive/MyDrive/CNN/Skin_Data_Store/Train\"\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  seed=123,\n",
    "  validation_split = 0.2,\n",
    "  subset = 'training',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwNJVDuBP5kf"
   },
   "source": [
    "#### Create a validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2602,
     "status": "ok",
     "timestamp": 1710154566296,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "TX191d_3dRW0",
    "outputId": "523923ff-029f-4fc8-a91e-4ca42440d598"
   },
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  seed=123,\n",
    "  validation_split = 0.2,\n",
    "  subset = 'validation',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JaoWeOEpVjqH"
   },
   "source": [
    "#### Create your model (make sure to include normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bu5N9LxkVx1B"
   },
   "source": [
    "#### Compile your model (Choose optimizer and loss function appropriately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 382,
     "status": "ok",
     "timestamp": 1710154573926,
     "user": {
      "displayName": "Mohi Shaik",
      "userId": "02999650142159302227"
     },
     "user_tz": -330
    },
    "id": "H47GWmLbdRW1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import legacy\n",
    "\n",
    "optimizer = legacy.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gS-Y1bJV7uy"
   },
   "source": [
    "####  Train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcV6OdI4dRW1",
    "outputId": "cb576780-2307-4b28-ca5d-8a7f9a92ec27"
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    factor=0.5,\n",
    "    min_lr=0.00001)\n",
    "\n",
    "batch_size = 10\n",
    "history = model.fit(train_ds,\n",
    "  epochs = epochs, verbose = 1, validation_data=val_ds , callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuvfCTsBWLMp"
   },
   "source": [
    "####  Visualize the model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "lCTXwfkTdRW1",
    "outputId": "8747ae63-ff2c-48ee-f34a-a129f5425cf8"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "source": [
    "#### Did you get rid of underfitting/overfitting? Did class rebalance help?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHKAWRZyfYlD"
   },
   "source": [
    "The class rebalance helped in reducing overfititng of the data and thus the loass is beng reduced\n",
    "But it reduced the Acurracy very low\n",
    "\n",
    "\n",
    "Initially we tried without the ImageDataGenerator which created data to over fit at high ratio\n",
    "\n",
    "Then we introduced dropout and ImageDataGenerator which reduced the over fit\n",
    "\n",
    "At last we tried Batch Normalization and Augumentation which really helped in carry forward"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "0-AUR_b7UcaK"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
